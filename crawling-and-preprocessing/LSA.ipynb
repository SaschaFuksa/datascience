{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                       place  \\\n0                    Waikiki   \n1           The Florida Keys   \n2  Yellowstone National Park   \n3             The Big Island   \n4           The Great Plains   \n\n                                           full_text  \n0  Built on a reclaimed swamp, two miles east of ...  \n1  Folklore, films and widespread hearsay have gi...  \n2  America’s oldest and easily its most famous na...  \n3  Although the Big Island of Hawaii could hold a...  \n4  The rolling hills and vast grasslands of the G...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>place</th>\n      <th>full_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Waikiki</td>\n      <td>Built on a reclaimed swamp, two miles east of ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The Florida Keys</td>\n      <td>Folklore, films and widespread hearsay have gi...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Yellowstone National Park</td>\n      <td>America’s oldest and easily its most famous na...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The Big Island</td>\n      <td>Although the Big Island of Hawaii could hold a...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The Great Plains</td>\n      <td>The rolling hills and vast grasslands of the G...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv('content/data_prep_2805_3.csv', usecols=['place', 'full_text'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords, strip_punctuation \\\n",
    "                                        , preprocess_string, strip_short, stem_text\n",
    "\n",
    "# preprocess given text\n",
    "def preprocess(text):\n",
    "\n",
    "    # clean text based on given filters\n",
    "    CUSTOM_FILTERS = [lambda x: x.lower(),\n",
    "                                remove_stopwords,\n",
    "                                strip_punctuation,\n",
    "                                strip_short,\n",
    "                                stem_text]\n",
    "    text = preprocess_string(text, CUSTOM_FILTERS)\n",
    "\n",
    "    return text\n",
    "\n",
    "# apply function to all reviews\n",
    "df['Text (Clean)'] = df['full_text'].apply(lambda x: preprocess(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "                       place  \\\n0                    Waikiki   \n1           The Florida Keys   \n2  Yellowstone National Park   \n3             The Big Island   \n4           The Great Plains   \n\n                                           full_text  \\\n0  Built on a reclaimed swamp, two miles east of ...   \n1  Folklore, films and widespread hearsay have gi...   \n2  America’s oldest and easily its most famous na...   \n3  Although the Big Island of Hawaii could hold a...   \n4  The rolling hills and vast grasslands of the G...   \n\n                                        Text (Clean)  \n0  [built, reclaim, swamp, mile, east, downtown, ...  \n1  [folklor, film, widespread, hearsai, given, fl...  \n2  [america’, oldest, easili, famou, nation, park...  \n3  [big, island, hawaii, hold, island, room, spar...  \n4  [roll, hill, vast, grassland, great, plain, ho...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>place</th>\n      <th>full_text</th>\n      <th>Text (Clean)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Waikiki</td>\n      <td>Built on a reclaimed swamp, two miles east of ...</td>\n      <td>[built, reclaim, swamp, mile, east, downtown, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The Florida Keys</td>\n      <td>Folklore, films and widespread hearsay have gi...</td>\n      <td>[folklor, film, widespread, hearsai, given, fl...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Yellowstone National Park</td>\n      <td>America’s oldest and easily its most famous na...</td>\n      <td>[america’, oldest, easili, famou, nation, park...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The Big Island</td>\n      <td>Although the Big Island of Hawaii could hold a...</td>\n      <td>[big, island, hawaii, hold, island, room, spar...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The Great Plains</td>\n      <td>The rolling hills and vast grasslands of the G...</td>\n      <td>[roll, hill, vast, grassland, great, plain, ho...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview of dataset\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# convert these processed reviews into a document-term matrix with the bag of words model\n",
    "from gensim import corpora\n",
    "\n",
    "# create a dictionary with the corpus\n",
    "corpus = df['Text (Clean)']\n",
    "dictionary = corpora.Dictionary(corpus)\n",
    "\n",
    "# convert corpus into a bag of words\n",
    "bow = [dictionary.doc2bow(text) for text in corpus]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence score with 2 clusters: 0.36221930499264315\n",
      "Coherence score with 3 clusters: 0.3592032540776124\n",
      "Coherence score with 4 clusters: 0.37950650628888916\n",
      "Coherence score with 5 clusters: 0.3668776376896482\n",
      "Coherence score with 6 clusters: 0.37730942565183817\n",
      "Coherence score with 7 clusters: 0.3515149180704032\n",
      "Coherence score with 8 clusters: 0.40015528487641583\n",
      "Coherence score with 9 clusters: 0.32717267859903676\n",
      "Coherence score with 10 clusters: 0.31403255693468285\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import LsiModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "# find the coherence score with a different number of topics\n",
    "for i in range(2,11):\n",
    "    lsi = LsiModel(bow, num_topics=i, id2word=dictionary)\n",
    "    coherence_model = CoherenceModel(model=lsi, texts=df['Text (Clean)'], dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    print('Coherence score with {} clusters: {}'.format(i, coherence_score))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# perform SVD on the bag of words with the LsiModel to extract 9 topics because of the highest coherence score\n",
    "lsi = LsiModel(bow, num_topics=9, id2word=dictionary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in 0: 0.283*\"citi\" + 0.197*\"the\" + 0.163*\"town\" + 0.150*\"place\" + 0.138*\"it’\".\n",
      "Words in 1: 0.368*\"citi\" + -0.211*\"town\" + -0.199*\"beach\" + 0.151*\"build\" + 0.151*\"mexico\".\n",
      "Words in 2: -0.280*\"berlin\" + 0.234*\"mexico\" + -0.179*\"centuri\" + 0.144*\"site\" + -0.142*\"museum\".\n",
      "Words in 3: 0.307*\"rio\" + -0.172*\"lake\" + 0.155*\"beach\" + 0.155*\"manau\" + 0.147*\"amazon\".\n",
      "Words in 4: 0.235*\"madrid\" + 0.213*\"san\" + -0.202*\"berlin\" + 0.201*\"plaza\" + -0.176*\"manau\".\n",
      "Words in 5: 0.219*\"beach\" + -0.168*\"chiapa\" + -0.164*\"maya\" + -0.163*\"berlin\" + -0.142*\"river\".\n",
      "Words in 6: 0.514*\"lake\" + 0.239*\"trail\" + 0.179*\"vallei\" + 0.166*\"hike\" + 0.156*\"park\".\n",
      "Words in 7: 0.313*\"beach\" + -0.201*\"river\" + -0.161*\"manau\" + -0.159*\"madrid\" + -0.151*\"amazon\".\n",
      "Words in 8: 0.206*\"san\" + 0.201*\"berlin\" + 0.160*\"cabo\" + 0.128*\"beach\" + 0.124*\"lo\".\n"
     ]
    }
   ],
   "source": [
    "# find the 5 words with the srongest association to the derived topics\n",
    "for topic_num, words in lsi.print_topics(num_words=5):\n",
    "    print('Words in {}: {}.'.format(topic_num, words))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# find the scores given between the place and each topic\n",
    "corpus_lsi = lsi[bow]\n",
    "score1 = []\n",
    "score2 = []\n",
    "score3 = []\n",
    "score4 = []\n",
    "score5 = []\n",
    "score6 = []\n",
    "score7 = []\n",
    "score8 = []\n",
    "score9 = []\n",
    "for doc in corpus_lsi:\n",
    "    score1.append(round(doc[0][1],2))\n",
    "    score2.append(round(doc[1][1],2))\n",
    "    score3.append(round(doc[2][1],2))\n",
    "    score4.append(round(doc[3][1],2))\n",
    "    score5.append(round(doc[4][1],2))\n",
    "    score6.append(round(doc[5][1],2))\n",
    "    score7.append(round(doc[6][1],2))\n",
    "    score8.append(round(doc[7][1],2))\n",
    "    score9.append(round(doc[8][1],2))\n",
    "\n",
    "\n",
    "# create data frame that shows scores assigned for both topics for each review\n",
    "df_topic = pd.DataFrame()\n",
    "df_topic['Text'] = df['full_text']\n",
    "df_topic['Topic 0 score'] = score1\n",
    "df_topic['Topic 1 score'] = score2\n",
    "df_topic['Topic 2 score'] = score3\n",
    "df_topic['Topic 3 score'] = score4\n",
    "df_topic['Topic 4 score'] = score5\n",
    "df_topic['Topic 5 score'] = score6\n",
    "df_topic['Topic 6 score'] = score7\n",
    "df_topic['Topic 7 score'] = score8\n",
    "df_topic['Topic 8 score'] = score9\n",
    "df_topic['Topic']= df_topic[['Topic 0 score', 'Topic 1 score', 'Topic 2 score', 'Topic 3 score', 'Topic 4 score', 'Topic 5 score', 'Topic 6 score', 'Topic 7 score', 'Topic 8 score']].apply(lambda x: x.argmax(), axis=1)\n",
    "df_topic.head(50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text from topic 0:\n",
      " ['A sprawling, hot and dusty city with over 400,000 inhabitants, PUCALLPA holds little of interest to travellers, most of whom get straight into a mototaxi or a local bus for Lago Yarinacocha. If you stay a while, though, it’s difficult not to appreciate Pucallpa’s relaxed feel – or the entrepreneurial optimism of this burgeoning jungle frontier city. Pucallpa’s annual festival for visitors – the Semana Turística de la Region Ucayali – is usually held in the last week of September, offering mostly artesanía and forest-produce markets, as well as folklore, music and dance.If you have an hour or so to while away in the town itself, both the downtown food market on Jirón Independencia and the older central market on Dos de Mayo are worth checking out; the latter in particular comprises varied stalls full of jungle produce. The port of La Hoyada and the older, nearby Puerto Italia are also bustling with activity by day. For craft shopping, artesanía can be found at Jirón Mariscal Cáceres block 5, Jirón Tarapacá block 8 and Jirón Tanca block 6.']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "a must be greater than 0 unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [34]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      3\u001B[0m df_topic1 \u001B[38;5;241m=\u001B[39m df_topic[df_topic[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTopic\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m==\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSample text from topic 0:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(df_topic0\u001B[38;5;241m.\u001B[39msample(\u001B[38;5;241m1\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mText\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mvalues))\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mSample text from topic 1:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[43mdf_topic1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msample\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mText\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mvalues))\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/generic.py:5446\u001B[0m, in \u001B[0;36mNDFrame.sample\u001B[0;34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001B[0m\n\u001B[1;32m   5443\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m weights \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   5444\u001B[0m     weights \u001B[38;5;241m=\u001B[39m sample\u001B[38;5;241m.\u001B[39mpreprocess_weights(\u001B[38;5;28mself\u001B[39m, weights, axis)\n\u001B[0;32m-> 5446\u001B[0m sampled_indices \u001B[38;5;241m=\u001B[39m \u001B[43msample\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj_len\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreplace\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   5447\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtake(sampled_indices, axis\u001B[38;5;241m=\u001B[39maxis)\n\u001B[1;32m   5449\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ignore_index:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/sample.py:150\u001B[0m, in \u001B[0;36msample\u001B[0;34m(obj_len, size, replace, weights, random_state)\u001B[0m\n\u001B[1;32m    147\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    148\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid weights: weights sum to zero\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 150\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchoice\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj_len\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreplace\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweights\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mastype(\n\u001B[1;32m    151\u001B[0m     np\u001B[38;5;241m.\u001B[39mintp, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    152\u001B[0m )\n",
      "File \u001B[0;32mmtrand.pyx:909\u001B[0m, in \u001B[0;36mnumpy.random.mtrand.RandomState.choice\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: a must be greater than 0 unless no samples are taken"
     ]
    }
   ],
   "source": [
    "# find a sample review from each topic\n",
    "df_topic0 = df_topic[df_topic['Topic'] == 0]\n",
    "df_topic1 = df_topic[df_topic['Topic']==1]\n",
    "print('Sample text from topic 0:\\n {}'.format(df_topic0.sample(1, random_state=2)['Text'].values))\n",
    "print('\\nSample text from topic 1:\\n {}'.format(df_topic1.sample(1, random_state=2)['Text'].values))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}